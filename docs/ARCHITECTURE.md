# Architecture Overview

## System Diagram

```
┌─────────────────────────────────────────────────────────────────────┐
│                     File Processing System                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  ┌──────────┐        ┌──────────┐        ┌──────────┐              │
│  │  Client  │───────>│   API    │───────>│  MinIO   │              │
│  │  (HTTP)  │        │  Server  │        │ Storage  │              │
│  └──────────┘        └──────────┘        └──────────┘              │
│                           │                                          │
│                           ├──────────────>┌──────────┐              │
│                           │               │PostgreSQL│              │
│                           │               └──────────┘              │
│                           │                                          │
│                           v                                          │
│                     ┌──────────┐                                    │
│                     │  Redis   │                                    │
│                     │ Streams  │                                    │
│                     └──────────┘                                    │
│                           │                                          │
│                           v                                          │
│                     ┌──────────┐        ┌──────────┐               │
│                     │  Worker  │───────>│Processor │               │
│                     │   Pool   │        │ Registry │               │
│                     └──────────┘        └──────────┘               │
│                           │                    │                     │
│                           v                    v                     │
│                     ┌──────────┐        ┌──────────┐               │
│                     │PostgreSQL│        │  MinIO   │               │
│                     │(variants)│        │(variants)│               │
│                     └──────────┘        └──────────┘               │
│                                                                       │
└─────────────────────────────────────────────────────────────────────┘
```

## Request Flow

### Upload Flow
1. Client uploads file via HTTP POST to `/api/upload`
2. API server validates file (size, type, auth)
3. File saved to MinIO storage: `{user_id}/{file_id}/original.{ext}`
4. File metadata inserted into PostgreSQL `files` table
5. Job payload created (ThumbnailPayload, ResizePayload)
6. Jobs enqueued to Redis Streams via broker
7. API returns 202 Accepted with file metadata and job IDs
8. Client receives response immediately (async processing)

### Processing Flow
1. Worker pool polls Redis Streams (every 1 second)
2. Worker picks up job from "default" queue
3. Middleware chain executes (recovery → logging → timeout)
4. Job handler executes:
   - Retrieves file metadata from database
   - Downloads original file from MinIO
   - Processes file using processor registry
   - Uploads variant to MinIO: `{user_id}/{file_id}/{variant_type}.{ext}`
   - Saves variant metadata to database
5. Job marked complete or retried on failure
6. Logs execution time and status

## Components

### API Server (`cmd/api`)
Entry point: `cmd/api/main.go`

Responsibilities:
- HTTP request handling (standard library `net/http`)
- Authentication (sessions for web, JWT for API)
- File upload validation
- Job enqueueing via broker adapter
- Serving web UI (templ templates)

Key packages:
- `internal/api` - REST API handlers
- `internal/web` - Web UI handlers
- `internal/auth` - Session and JWT middleware
- `internal/apperror` - Error responses

### Worker Pool (`cmd/worker`)
Entry point: `cmd/worker/main.go`

Responsibilities:
- Job consumption from Redis Streams
- Concurrent processing (default: 4 workers)
- Error handling and retries
- Graceful shutdown (30s timeout)

Key packages:
- `internal/worker` - Job handlers and payloads
- `github.com/abdul-hamid-achik/job-queue` - Queue library

### Storage Layer (`internal/storage`)
Interface: `storage.Storage`

Implementation: MinIO client (S3-compatible)

Operations:
- `Upload(ctx, path, reader, contentType, size)` - Save file
- `Download(ctx, path)` - Retrieve file
- `Delete(ctx, path)` - Remove file
- `URL(ctx, path, expires)` - Generate presigned URL

### Database Layer (`internal/db`)
Generated by sqlc from SQL queries

Tables:
- `users` - User accounts
- `sessions` - Web UI sessions
- `oauth_accounts` - OAuth providers
- `api_tokens` - JWT tokens
- `files` - File metadata
- `file_variants` - Processed variants
- `processing_jobs` - Job tracking
- `password_resets` - Password reset tokens
- `email_verifications` - Email verification tokens

### Processor Registry (`internal/processor`)
Pattern: Strategy pattern for pluggable processors

Available processors:
- `thumbnail` - 300x300 image thumbnails
- `resize` - Multiple size variants
- `webp` - WebP conversion
- `watermark` - Image watermarking
- `pdf_thumbnail` - PDF first page thumbnail

Interface:
```go
type Processor interface {
    Process(ctx context.Context, opts *Options, input io.Reader) (*Result, error)
    SupportedTypes() []string
    Name() string
}
```

PDF processor uses `poppler-utils` (pdftoppm, pdfinfo) for rendering.

### Job Queue (`github.com/abdul-hamid-achik/job-queue`)
Architecture: Redis Streams with consumer groups

Components:
- `broker.RedisStreamsBroker` - Job enqueueing/dequeueing
- `worker.Pool` - Worker pool management
- `job.Job` - Job structure (ID, type, payload, queue, timestamp)
- `middleware` - Recovery, logging, timeout

Payloads:
```go
type ThumbnailPayload struct {
    FileID  uuid.UUID
    Width   int
    Height  int
    Quality int
}

type ResizePayload struct {
    FileID      uuid.UUID
    Width       int
    Height      int
    Quality     int
    VariantType string
}

type PDFThumbnailPayload struct {
    FileID  uuid.UUID
    Page    int       // 1-based page number
    Width   int
    Height  int
    Quality int
    Format  string    // "png" or "jpeg"
}
```

## Authentication

### Session-Based (Web UI)
Flow:
1. User submits login form
2. Password verified via bcrypt
3. Session created in database
4. httpOnly cookie set with session ID
5. Middleware validates session on each request

Implementation: `internal/auth/session.go`

### JWT-Based (API)
Flow:
1. Client POSTs credentials to `/api/auth/login`
2. Server validates and returns JWT token
3. Client includes `Authorization: Bearer <token>` header
4. Middleware validates JWT signature and expiry

Implementation: `internal/auth/middleware.go`

### OAuth (Web UI only)
Providers: Google, GitHub

Flow:
1. User clicks OAuth button
2. Redirected to provider
3. Callback receives code
4. Server exchanges code for user info
5. User created/linked in database
6. Session created and cookie set

Implementation: `internal/auth/oauth.go`

## Configuration

Loaded from environment variables via `.env` file

Required:
- `DATABASE_URL` - PostgreSQL connection
- `REDIS_URL` - Redis connection
- `MINIO_ENDPOINT` - MinIO endpoint
- `MINIO_ACCESS_KEY` - MinIO access key
- `MINIO_SECRET_KEY` - MinIO secret key
- `JWT_SECRET` - JWT signing secret

Optional:
- `WORKER_CONCURRENCY` - Worker pool size (default: 4)
- `JOB_TIMEOUT` - Max job duration (default: 5m)
- `MAX_RETRIES` - Max retry attempts (default: 3)
- `LOG_LEVEL` - Logging level (debug, info, warn, error)
- `GOOGLE_CLIENT_ID` - Google OAuth
- `GITHUB_CLIENT_ID` - GitHub OAuth

## Deployment

Services required:
- PostgreSQL 16+
- Redis 7+
- MinIO (or S3-compatible storage)

Components to run:
- API server: `./bin/api`
- Worker pool: `./bin/worker`

Development:
```bash
task docker:up      # Start services
task run:api        # Start API server
task run:worker     # Start worker pool
```

Production:
```bash
task build          # Build binaries to bin/
./bin/api &         # Run API server
./bin/worker &      # Run worker pool
```

## Observability

### Logging
Library: Go's `log/slog` via `internal/logger`

Format:
- Development: text (colorized)
- Production: JSON (structured)

Context fields:
- `request_id` - Request trace ID
- `user_id` - Authenticated user ID
- `job_id` - Background job ID
- `duration` - Operation duration

### Metrics
Stack: Grafana + Loki + Promtail (configured in `docker-compose.yml`)

Logs shipped to Loki for aggregation and querying

### Error Tracking
All errors use `internal/apperror` package

Error types:
- Permanent errors (non-retryable)
- Transient errors (retryable)
- User-facing errors (safe messages)
- Internal errors (logged with full context)

## Scaling Considerations

### Horizontal Scaling
API server:
- Stateless (sessions in database)
- Can run multiple instances behind load balancer
- No shared state between instances

Worker pool:
- Consumer groups prevent duplicate processing
- Can run multiple worker pools
- Jobs distributed across workers

### Vertical Scaling
Bottlenecks:
- Database connections (configure pool size)
- MinIO bandwidth (use CDN for downloads)
- Worker concurrency (tune `WORKER_CONCURRENCY`)

### Storage
MinIO:
- Supports distributed mode for HA
- Can use S3 for managed storage
- Presigned URLs offload download traffic

### Database
PostgreSQL:
- Indexes on foreign keys
- Partitioning for large tables (files, variants)
- Read replicas for reporting queries
